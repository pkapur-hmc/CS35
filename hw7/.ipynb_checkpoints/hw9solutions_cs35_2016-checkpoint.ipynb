{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to OpenCV - solutions for wk9 (cs35 spring 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### look below - the solutions to each of the three problems is marked with a markdown cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check that you have opencv:\n",
    "import cv2\n",
    "\n",
    "# if not, try closing ipython notebook and running this installation command:\n",
    "# conda install -c https://conda.binstar.org/menpo opencv  (then restart)\n",
    "\n",
    "# documentation for OpenCV:   http://docs.opencv.org/2.4/index.html\n",
    "# tutorials are in many places, e.g., http://docs.opencv.org/3.1.0/d6/d00/tutorial_py_root.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# other libraries that will be needed\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " # not going to use %matplotlib inline so that we have more control!\n",
    "%matplotlib  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Images as pictures: reading, writing, and resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# options include cv2.IMREAD_COLOR # color, with no alpha channel\n",
    "# also cv2.IMREAD_GRAYSCALE (== 0)\n",
    "# or cv2.IMREAD_UNCHANGED (includes alpha)\n",
    "\n",
    "# Reading and color-converting an image to RGB\n",
    "raw_image = cv2.imread('messi5.jpg',cv2.IMREAD_COLOR) \n",
    "raw_image = cv2.imread('monalisa.jpg',cv2.IMREAD_COLOR) \n",
    "\n",
    "# convert an OpenCV image (BGR) to an \"ordinary\" image (RGB) \n",
    "image = cv2.cvtColor(raw_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.imshow(image)    # plt.xticks([]), plt.yticks([])  # to hide axis labels\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let's get the flag image next\n",
    "raw_image = cv2.imread('flag.jpg',cv2.IMREAD_COLOR)\n",
    "flag = cv2.cvtColor(raw_image, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(flag) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flag.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# want to write out a new image - no problem:\n",
    "small_image = cv2.resize(flag, dsize=(50,50))  \n",
    "# there are three resize algorithms, described here:\n",
    "# docs.opencv.org/2.4/modules/imgproc/doc/geometric_transformations.html?highlight=resize#cv2.resize\n",
    "raw_small_image = cv2.cvtColor(small_image, cv2.COLOR_RGB2BGR)\n",
    "cv2.imwrite( \"small.png\", raw_small_image )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# re-read to check the small image:\n",
    "raw_small = cv2.imread('small.png',cv2.IMREAD_COLOR)\n",
    "small = cv2.cvtColor(raw_small, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(small) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Images as pixels: accessing their individual components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# two more images...\n",
    "raw_image_flag = cv2.imread('flag.jpg',cv2.IMREAD_COLOR) \n",
    "raw_image_spam = cv2.imread('spam.png',cv2.IMREAD_COLOR) \n",
    "\n",
    "fimage = cv2.cvtColor(raw_image_flag, cv2.COLOR_BGR2RGB)\n",
    "simage = cv2.cvtColor(raw_image_spam, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a truly pixel-for-pixel rendering using an OpenCV window\n",
    "cv2.namedWindow('opencvwindow', cv2.WINDOW_AUTOSIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#nimage = cv2.cvtColor(resized_img, cv2.COLOR_BGR2RGB)\n",
    "cv2.imshow('opencvwindow',raw_image_flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# blur - a common photoshop filter...\n",
    "blurred_flag = cv2.blur( simage, (2,2) )  # 16 pixel average (each direction)\n",
    "plt.imshow(blurred_flag) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# but we want to be able to go _beyond_ Photoshop (as needed...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let's split our image into three \"channels\"\n",
    "image = simage\n",
    "#image_r, image_g, image_b = cv2.split( image )  # the three channels OR\n",
    "image_r = image[:,:,0]  # red\n",
    "image_g = image[:,:,1]  # gre\n",
    "image_b = image[:,:,2]  # blu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(simage) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let's see each of these three \"channels\" separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# here is a 2d layout of images:\n",
    "image = simage\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, sharex=False, sharey=False)\n",
    "ax[0].imshow(image);  ax[0].set_title(\"orig\");  ax[0].axis('off')\n",
    "ax[1].imshow(image_b, cmap='gray');   ax[1].set_title(\"blue channel alone\"); ax[1].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# try the flag-channel challenge..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# here is a 2d layout of images:\n",
    "image = fimage\n",
    "image_r = image[:,:,0]  # red\n",
    "image_g = image[:,:,1]  # gre\n",
    "image_b = image[:,:,2]  # blu\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, ncols=2, sharex=False, sharey=False)\n",
    "ax[0,0].imshow(image);  #ax[0,0].set_title(\"orig\")\n",
    "ax[0,1].imshow(image_b, cmap='gray');  #ax[0,1].set_title(\"red\")\n",
    "ax[1,0].imshow(image_r, cmap='gray');  #ax[1,0].set_title(\"green\")\n",
    "ax[1,1].imshow(image_g, cmap='gray');  #ax[1,1].set_title(\"blue\")\n",
    "for row in range(2):\n",
    "    for col in range(2):\n",
    "        ax[row,col].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### an example of a color conversion in OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# color conversions are here:\n",
    "# http://docs.opencv.org/3.1.0/d7/d1b/group__imgproc__misc.html#gsc.tab=0\n",
    "image = fimage\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "plt.imshow(gray_image, cmap='gray', vmin=0, vmax=255)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# what will happen here?\n",
    "gray2 = gray_image//2\n",
    "plt.imshow(gray2, cmap='gray', vmin=0, vmax=255)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### examples of thresholding images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### numpy's benefit: full-array operations in one expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# numpy arrays are cleverer than plain lists...\n",
    "a = np.array( [ [1,2,3], [4,5,6], [7,8,9] ] )\n",
    "print(a)\n",
    "indices = a < 4.5\n",
    "print(indices)\n",
    "a[indices] = 0\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# types are important!\n",
    "# numpy types: http://docs.scipy.org/doc/numpy-1.10.1/user/basics.types.html\n",
    "a = a.astype(float)\n",
    "print(a)\n",
    "a = a.astype(int)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### let's try with images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# here are some thresholded images\n",
    "image_gt142_indices = gray_image > 142\n",
    "image_gt142 = image.copy()\n",
    "image_gt142[image_gt142_indices] = 255\n",
    "image_gt142[np.logical_not(image_gt142_indices)] = 0\n",
    "# note that this shows how to take logical operators of index arrays..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(image_gt142, cmap='gray', vmin=0, vmax=255)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# you might try the thresholding challenge in the slides (with the spam image) here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# here are some thresholded images\n",
    "image_lt42_indices = gray_image < 42\n",
    "image_lt42 = image.copy()\n",
    "image_lt42[image_lt42_indices] = 255\n",
    "image_lt42[np.logical_not(image_lt42_indices)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_not_btw_42_142_indices = \\\n",
    "  np.logical_or(image_gt142_indices,image_lt42_indices)\n",
    "image_btw_42_142 = image.copy()\n",
    "image_btw_42_142[image_not_btw_42_142_indices] = 0\n",
    "image_btw_42_142[np.logical_not(image_not_btw_42_142_indices)] = 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# here is a 2d layout of images:\n",
    "fig, ax = plt.subplots(nrows=2, ncols=2, sharex=False, sharey=False)\n",
    "ax[0,0].imshow(image, cmap='gray');  #ax[0,0].set_title(\"orig\")\n",
    "ax[0,1].imshow(image_gt142, cmap='gray');  #ax[1,1].set_title(\"blue\")\n",
    "ax[1,0].imshow(image_btw_42_142, cmap='gray');  #ax[1,0].set_title(\"green\")\n",
    "ax[1,1].imshow(image_lt42, cmap='gray');  #ax[0,1].set_title(\"red\")\n",
    "\n",
    "for row in range(2):\n",
    "    for col in range(2):\n",
    "        ax[row,col].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fig = plt.figure()  # gets a new figure window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### let's try some of our own transformations..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for loops over the image - an all-blue image\n",
    "def example_filter( image ):\n",
    "    \"\"\" an example of a pixel-by-pixel filter \n",
    "        input: an r, g, b image\n",
    "        output: a transformed r, g, b image\n",
    "    \"\"\"\n",
    "    new_image = image.copy()\n",
    "    num_rows, num_cols, num_chans = new_image.shape\n",
    "    for row in range(num_rows):\n",
    "        for col in range(num_cols):\n",
    "            r, g, b = image[row,col]\n",
    "            new_image[row,col] = [b, b, b]\n",
    "    return new_image\n",
    "\n",
    "imge = fimage\n",
    "new_image = example_filter( image )\n",
    "plt.imshow(new_image)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution to problem #1 - example filters\n",
    "The starter file provided these, and students were invited to create two additional filters: one\n",
    "that transformed a single image; one that composited two images together (in some way)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# image filters (transformations from image to image)\n",
    "\n",
    "# for loops over the image\n",
    "def example_filter_bgr( image ):\n",
    "    \"\"\" an example of a pixel-by-pixel filter \n",
    "        input: an r, g, b image\n",
    "        output: a transformed r, g, b image\n",
    "    \"\"\"\n",
    "    new_image = image.copy()\n",
    "    num_rows, num_cols, num_chans = new_image.shape\n",
    "    for row in range(num_rows):\n",
    "        for col in range(num_cols):\n",
    "            r, g, b = image[row,col]\n",
    "            new_image[row,col] = [b, g, r]\n",
    "    return new_image\n",
    "\n",
    "\n",
    "def example_filter_gbr( image ):\n",
    "    \"\"\" an example of a pixel-by-pixel filter \n",
    "        input: an r, g, b image\n",
    "        output: a transformed r, g, b image\n",
    "    \"\"\"\n",
    "    new_image = image.copy()\n",
    "    num_rows, num_cols, num_chans = new_image.shape\n",
    "    for row in range(num_rows):\n",
    "        for col in range(num_cols):\n",
    "            r, g, b = image[row,col]\n",
    "            new_image[row,col] = [g, b, r]\n",
    "    return new_image\n",
    "\n",
    "\n",
    "def example_filter_inv( image ):\n",
    "    \"\"\" an example of a pixel-by-pixel filter \n",
    "        input: an r, g, b image\n",
    "        output: a transformed r, g, b image\n",
    "    \"\"\"\n",
    "    new_image = image.copy()\n",
    "    num_rows, num_cols, num_chans = new_image.shape\n",
    "    for row in range(num_rows):\n",
    "        for col in range(num_cols):\n",
    "            r, g, b = image[row,col]\n",
    "            new_image[row,col] = [255-r, 255-g, 255-b]\n",
    "    return new_image\n",
    "\n",
    "def example_filter_ig( image ):\n",
    "    \"\"\" an example of a pixel-by-pixel filter \n",
    "        input: an r, g, b image\n",
    "        output: a transformed r, g, b image\n",
    "    \"\"\"\n",
    "    new_image = image.copy()\n",
    "    num_rows, num_cols, num_chans = new_image.shape\n",
    "    for row in range(num_rows):\n",
    "        for col in range(num_cols):\n",
    "            r, g, b = image[row,col]\n",
    "            new_image[row,col] = [r, 255-g, b]\n",
    "    return new_image\n",
    "\n",
    "def example_filter_delbot2( image ):\n",
    "    \"\"\" an example of a pixel-by-pixel filter \n",
    "        input: an r, g, b image\n",
    "        output: a transformed r, g, b image\n",
    "    \"\"\"\n",
    "    new_image = image.copy()\n",
    "    num_rows, num_cols, num_chans = new_image.shape\n",
    "    for row in range(num_rows):\n",
    "        for col in range(num_cols):\n",
    "            r, g, b = image[row,col]\n",
    "            new_image[row,col] = [r>>2 << 2, g>>2<<2, b>>2 << 2]\n",
    "    return new_image\n",
    "\n",
    "def example_filter_deltop2( image ):\n",
    "    \"\"\" an example of a pixel-by-pixel filter \n",
    "        input: an r, g, b image\n",
    "        output: a transformed r, g, b image\n",
    "    \"\"\"\n",
    "    new_image = image.copy()\n",
    "    num_rows, num_cols, num_chans = new_image.shape\n",
    "    for row in range(num_rows):\n",
    "        for col in range(num_cols):\n",
    "            r, g, b = image[row,col]\n",
    "            new_image[row,col] = [r>>2 , g>>2, b>>2 ]\n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run all of these..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1:  write-your-own-filter\n",
    "\n",
    "Part A will be at least one filter that takes in a single image, transforms its pixels in an unusual way (something not in Photoshop's menu options, perhaps?), and then runs that filter on at least two of your own images.\n",
    "\n",
    "Part B will ask you to create at least one filter -- but one that combines _two_ images, meshing their pixels in a creative way, and outputting a single image. It's OK to resize the images so that they;re the same shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use the above examples as a starting point..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_filter( image ):\n",
    "    \"\"\" better docstring needed! \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def two_image_filter( image1, image2 ):\n",
    "    \"\"\" better docstring needed! \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2:  steganography\n",
    "\n",
    "This question asks you to write two functions, likely with some helper functions, that will enable you\n",
    "to embed arbitrary text (string) messages into an image (if there is enough room!) -- and then be\n",
    "able to extract an embedded message from an image, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let's do steganography!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# here is a signature for the encoding/embedding\n",
    "def steganographize( image, message ):\n",
    "    \"\"\" be sure to include a better docstring here! \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# here is a signature for the decoding\n",
    "def desteg_string( image ):\n",
    "    \"\"\" be sure to include a better docstring here! \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use the small image for testing\n",
    "raw_small = cv2.imread(\"small.png\",cv2.IMREAD_COLOR)\n",
    "small = cv2.cvtColor(raw_small, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(small)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 37, 138, 175],\n",
       "       [ 27, 139, 177],\n",
       "       [ 28, 142, 183]], dtype=uint8)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small[0,0:3,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0b100100'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin(36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 36, 139, 174],\n",
       "       [ 27, 138, 177],\n",
       "       [ 29, 143, 182]], dtype=uint8)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_small[0,0:3,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N, AB is 136 0101011101001111010101110010000001110100011010000110100101110011001000000111011101101111011100100110101101100101011001000010000100000000\n",
      "new_image.shape is (50, 50, 3)\n"
     ]
    }
   ],
   "source": [
    "# run steganographize\n",
    "new_small = steganographize( small, \"WOW this worked!\" )\n",
    "plt.imshow(new_small)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WOW this worked!'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desteg_string( new_small )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# be sure to delete this! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution to problem #2 - steganography\n",
    "Below is steganographize (with a pretty weak docstring!) It does have some helper functions, as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# steganography question (extra - more bits or color)\n",
    "def conv_to_bits( c ):\n",
    "    \"\"\" returns the bits of c (always 8 bits) \"\"\"\n",
    "    if type(c) == type(42):\n",
    "        binary = bin(c)\n",
    "    else:\n",
    "        c = c[0:1]\n",
    "        if len(c) == 0: return '00000000'\n",
    "        binary = bin( ord(c) )\n",
    "    binary = binary[2:] # pull off the '0b'\n",
    "    # only keep 8 bits\n",
    "    b = binary[:8]\n",
    "    # add more bits (zeros) to the left\n",
    "    b = '0'*(8-len(b)) + b\n",
    "    return b\n",
    "\n",
    "def all_to_bits( s ):\n",
    "    \"\"\" string to bits! \"\"\"\n",
    "    list_of_bitstrings = [ conv_to_bits(c) for c in s ]\n",
    "    return ''.join(list_of_bitstrings)\n",
    "    \n",
    "def steganographize( image, message ):\n",
    "    \"\"\" does just that!\n",
    "        message can be a string or an image\n",
    "    \"\"\"\n",
    "    if type(message) == type(''): # handle string message\n",
    "        AB = all_to_bits(message) + '00000000' # ending!\n",
    "        pass\n",
    "    else: # image case\n",
    "        AB = '00000000'\n",
    "    \n",
    "    i = 0\n",
    "    N = len(AB)\n",
    "    print(\"N, AB is\", N, AB)\n",
    "    new_image = image.copy()\n",
    "    num_rows, num_cols, num_chans = new_image.shape\n",
    "    print(\"new_image.shape is\", new_image.shape)\n",
    "    for row in range(num_rows):\n",
    "        for col in range(num_cols):\n",
    "            for chan in range(num_chans):\n",
    "                pix = image[row,col,chan]\n",
    "                b = int(AB[i])\n",
    "                if pix%2 != b:\n",
    "                    if b == 0:\n",
    "                        new_image[row,col,chan] = pix-1\n",
    "                    else:\n",
    "                        new_image[row,col,chan] = pix+1\n",
    "                i += 1\n",
    "                if i >= N: break\n",
    "            if i >= N: break\n",
    "        if i >= N: break\n",
    "            \n",
    "    return new_image\n",
    "\n",
    "def get_str( bit_string ):\n",
    "    s = bit_string\n",
    "    CHARS = []\n",
    "    while len( s ) >= 8:\n",
    "        c = chr( int( s[:8], 2) )\n",
    "        CHARS.append( c )\n",
    "        s = s[8:]\n",
    "    return ''.join(CHARS)\n",
    "        \n",
    "\n",
    "def desteg_string( image ):\n",
    "    \"\"\" undoes it! \"\"\"\n",
    "    bits = []\n",
    "    num_rows, num_cols, numchans = image.shape\n",
    "    for row in range(num_rows):\n",
    "        for col in range(num_cols):\n",
    "            r, g, b = image[row,col]\n",
    "            rb = str(r%2)\n",
    "            gb = str(g%2)\n",
    "            bb = str(b%2)\n",
    "            bits.extend( [rb,gb,bb] )\n",
    "    AB = ''.join(bits)\n",
    "    i = AB.find('00000000')\n",
    "    AB = AB[:i]\n",
    "    s = get_str(AB)\n",
    "    return s\n",
    "    \n",
    "    \n",
    "def desteg_image( image ):\n",
    "    \"\"\" undoes it! \"\"\"\n",
    "    pass\n",
    "\n",
    "#steganographize( image, 'hi!' )\n",
    "# new_image = example_filter( image )\n",
    "# plt.imshow(new_image)\n",
    "# plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "small[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_small = steganographize( small, \"WOW this worked!\" )\n",
    "plt.imshow(new_small)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_small[:1,:6,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "small[:1,:6,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "desteg_string( new_small )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "small_image = cv2.resize(image, dsize=(50,50))\n",
    "raw_small_image = cv2.cvtColor(small_image, cv2.COLOR_RGB2BGR)\n",
    "cv2.imwrite( \"small.png\", raw_small_image )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conv_to_bits('apple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "415*625*3/8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open(\"randj.txt\", \"r\")\n",
    "randj = f.read()\n",
    "f.close()\n",
    "print(len(randj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_fimage = steganographize( fimage, \"WOW this worked!\" )\n",
    "plt.imshow(new_fimage)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "desteg_string( new_fimage )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt4Agg\n"
     ]
    }
   ],
   "source": [
    "# examples for Wednesday's class...\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let's get the portions of original.jpg\n",
    "raw_image = cv2.imread('original.png',cv2.IMREAD_COLOR) \n",
    "image = cv2.cvtColor(raw_image, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(image)    # plt.xticks([]), plt.yticks([])  # to hide axis labels\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(373, 300, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape # 10,10 to 180 290"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_image = image[10:180,10:290,:]\n",
    "bot_image = image[190:360,10:290,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(170, 280, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot_image.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(top_image)    # plt.xticks([]), plt.yticks([])  # to hide axis labels\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bad_gs1( image ):\n",
    "    \"\"\" returns an image with green zero'd out\n",
    "    \"\"\"\n",
    "    new_image = image.copy()\n",
    "    \n",
    "    num_rows, num_cols, num_chans = new_image.shape\n",
    "    print(\"new_image.shape is\", new_image.shape)\n",
    "    for row in range(num_rows):\n",
    "        for col in range(num_cols):\n",
    "            r, g, b = image[row,col]\n",
    "            if g > 100:\n",
    "                new_image[row,col,:] = [0,0,0] \n",
    "            \n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution to problem #3 (part 1) - green-screening\n",
    "The function below finds all of the green pixels -- look down a bit to find place_gs, the function that places the green-screened image onto a new background..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def zero_green( image ):\n",
    "    \"\"\" returns an image with green zero'd out\n",
    "    \"\"\"\n",
    "    new_image = image.copy()\n",
    "    hsv_image = cv2.cvtColor( new_image, cv2.COLOR_RGB2HSV )\n",
    "    \n",
    "    num_rows, num_cols, num_chans = new_image.shape\n",
    "    print(\"new_image.shape is\", new_image.shape)\n",
    "    for row in range(num_rows):\n",
    "        for col in range(num_cols):\n",
    "            r, g, b = image[row,col]\n",
    "            h, s, v = hsv_image[row,col]\n",
    "            if (55 < h < 95 and s > 220 and v > 20) or (r < 5 and  g > 90 and b > 10): \n",
    "                new_image[row,col,:] = [0,255,0] \n",
    "            \n",
    "    return new_image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "hsv_image = cv2.cvtColor( top_image, cv2.COLOR_RGB2HSV )\n",
    "plt.imshow(hsv_image)    # plt.xticks([]), plt.yticks([])  # to hide axis labels\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_image.shape is (170, 280, 3)\n"
     ]
    }
   ],
   "source": [
    "new_im = zero_green(top_image)\n",
    "plt.imshow(new_im)    # plt.xticks([]), plt.yticks([])  # to hide axis labels\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub_im = new_im[20:150, 120:175, :]\n",
    "plt.imshow(sub_im)    # plt.xticks([]), plt.yticks([])  # to hide axis labels\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# background image\n",
    "raw_image = cv2.imread('pitzer_grounds.jpg',cv2.IMREAD_COLOR) \n",
    "image = cv2.cvtColor(raw_image, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(image)    # plt.xticks([]), plt.yticks([])  # to hide axis labels\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "smaller_sub_im =cv2.resize(sub_im, dsize=(0,0), fx=.5, fy=.5)\n",
    "plt.imshow(smaller_sub_im)    # plt.xticks([]), plt.yticks([])  # to hide axis labels\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bg_image = image.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs_image = sub_im.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution to problem #3 (part 2) - background overlay\n",
    "The function below places the green-screen-extracted image (gs) onto the background (bg) at location (pt). Note that cropping is simple with numpy arrays (simply slice to crop!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def place_gs( gs, bg, pt=(0,0) ):\n",
    "    \"\"\" docstring! \"\"\"\n",
    "    ulx = pt[0]\n",
    "    uly = pt[1]\n",
    "    \n",
    "    out = bg.copy()\n",
    "    \n",
    "    num_rows, num_cols, num_chans = gs.shape\n",
    "    num_rows2, num_cols2, num_chans2 = bg.shape\n",
    "    for row in range(uly,min(num_rows2,uly+num_rows)):\n",
    "        for col in range(ulx,min(num_cols2,ulx+num_cols)):\n",
    "            r, g, b = gs[row-uly,col-ulx]\n",
    "            if r == 0 and g == 255 and b == 0:\n",
    "                pass\n",
    "            else:\n",
    "                out[row,col,:] = gs[row-uly,col-ulx]\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(bg_image)    # plt.xticks([]), plt.yticks([])  # to hide axis labels\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bg_img_sm = cv2.resize(bg_image, dsize=(400,300))\n",
    "plt.imshow(bg_img_sm)    # plt.xticks([]), plt.yticks([])  # to hide axis labels\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_small_image = cv2.cvtColor(bg_img_sm, cv2.COLOR_RGB2BGR)\n",
    "cv2.imwrite( \"pitzer_park_sm.png\", raw_small_image )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "comp = place_gs(gs_image, bg_img_sm, (10,160))\n",
    "plt.imshow(comp)    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67\n"
     ]
    }
   ],
   "source": [
    "print( ord('C') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0b1000011'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin(67)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
