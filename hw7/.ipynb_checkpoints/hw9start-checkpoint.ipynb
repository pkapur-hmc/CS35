{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check that you have opencv:\n",
    "import cv2\n",
    "\n",
    "# if not, try closing ipython notebook and running this installation command:\n",
    "# conda install -c https://conda.binstar.org/menpo opencv  (then restart)\n",
    "\n",
    "# documentation for OpenCV:   http://docs.opencv.org/2.4/index.html\n",
    "# tutorials are in many places, e.g., http://docs.opencv.org/3.1.0/d6/d00/tutorial_py_root.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# other libraries that will be needed\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt4Agg\n"
     ]
    }
   ],
   "source": [
    " # not going to use %matplotlib inline so that we have more control!\n",
    "%matplotlib  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Owner\\\\Desktop\\\\hw9v1'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Images as pictures: reading, writing, and resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reading and color-converting an image to RGB\n",
    "\n",
    "# options include cv2.IMREAD_COLOR # color, with no alpha channel\n",
    "# also cv2.IMREAD_GRAYSCALE (== 0)\n",
    "# or cv2.IMREAD_UNCHANGED (includes alpha)\n",
    "\n",
    "raw_image = cv2.imread('messi5.jpg',cv2.IMREAD_COLOR) \n",
    "raw_image = cv2.imread('monalisa.jpg',cv2.IMREAD_COLOR) \n",
    "image = raw_image\n",
    "\n",
    "# convert an OpenCV image (BGR) to an \"ordinary\" image (RGB) \n",
    "image = cv2.cvtColor(raw_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.imshow(image)    # plt.xticks([]), plt.yticks([])  # to hide axis labels\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what _kind_ of thing is image or raw_image \n",
    "type(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(599, 396, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some pieces of information about our image\n",
    "# the \"shape\" is the number of rows, the number of cols, and the number of \"channels\":\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image[42,100] is [165 137  54]\n",
      "and has r, g, b =  165 137 54\n"
     ]
    }
   ],
   "source": [
    "# this accesses a single pixel at row 42, col 100\n",
    "print(\"image[42,100] is\", image[42,100])\n",
    "r, g, b = image[42, 100]\n",
    "print(\"and has r, g, b = \", r, g, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we can look for more pixel-level features using numpy indexing and slicing\n",
    "# try the \"follow the data\" challenge in the slides..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let's get the flag image next\n",
    "raw_image = cv2.imread('flag.jpg',cv2.IMREAD_COLOR)\n",
    "flag = cv2.cvtColor(raw_image, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(flag) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# want to write out a new image - no problem:\n",
    "small_image = cv2.resize(flag, dsize=(50,50))  \n",
    "# there are three resize algorithms, described here:\n",
    "# docs.opencv.org/2.4/modules/imgproc/doc/geometric_transformations.html?highlight=resize#cv2.resize\n",
    "raw_small_image = cv2.cvtColor(small_image, cv2.COLOR_RGB2BGR)\n",
    "cv2.imwrite( \"small.png\", raw_small_image )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# re-read to check the small image:\n",
    "raw_small = cv2.imread('small.png',cv2.IMREAD_COLOR)\n",
    "small = cv2.cvtColor(raw_small, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(small) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Images as pixels: accessing their individual components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# two more images...\n",
    "raw_image_flag = cv2.imread('flag.jpg',cv2.IMREAD_COLOR) \n",
    "raw_image_spam = cv2.imread('spam.png',cv2.IMREAD_COLOR) \n",
    "\n",
    "fimage = cv2.cvtColor(raw_image_flag, cv2.COLOR_BGR2RGB)\n",
    "simage = cv2.cvtColor(raw_image_spam, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a truly pixel-for-pixel rendering using an OpenCV window\n",
    "cv2.namedWindow('opencvwindow', cv2.WINDOW_AUTOSIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#nimage = cv2.cvtColor(resized_img, cv2.COLOR_BGR2RGB)\n",
    "cv2.imshow('opencvwindow',raw_image_flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# blur - a common photoshop filter...\n",
    "blurred_flag = cv2.blur( fimage, (16,16) )  # 16 pixel average (each direction)\n",
    "plt.imshow(blurred_flag) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# but we want to be able to go _beyond_ Photoshop (as needed...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let's split our image into three \"channels\"\n",
    "image = simage\n",
    "#image_r, image_g, image_b = cv2.split( image )  # the three channels OR\n",
    "image_r = image[:,:,0]  # red\n",
    "image_g = image[:,:,1]  # gre\n",
    "image_b = image[:,:,2]  # blu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let's see each of these three \"channels\" separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# here is a 2d layout of images:\n",
    "image = simage\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, sharex=False, sharey=False)\n",
    "ax[0].imshow(image);  ax[0].set_title(\"orig\");  ax[0].axis('off')\n",
    "ax[1].imshow(image_r, cmap='gray');   ax[1].set_title(\"red channel alone\"); ax[1].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# try the flag-channel challenge..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# here is a 2d layout of images:\n",
    "image = fimage\n",
    "image_r = image[:,:,0]  # red\n",
    "image_g = image[:,:,1]  # gre\n",
    "image_b = image[:,:,2]  # blu\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, ncols=2, sharex=False, sharey=False)\n",
    "ax[0,0].imshow(image);  #ax[0,0].set_title(\"orig\")\n",
    "ax[0,1].imshow(image_b, cmap='gray');  #ax[0,1].set_title(\"red\")\n",
    "ax[1,0].imshow(image_r, cmap='gray');  #ax[1,0].set_title(\"green\")\n",
    "ax[1,1].imshow(image_g, cmap='gray');  #ax[1,1].set_title(\"blue\")\n",
    "for row in range(2):\n",
    "    for col in range(2):\n",
    "        ax[row,col].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### an example of a color conversion in OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# color conversions are here:\n",
    "# http://docs.opencv.org/3.1.0/d7/d1b/group__imgproc__misc.html#gsc.tab=0\n",
    "image = fimage\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "plt.imshow(gray_image, cmap='gray', vmin=0, vmax=255)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# what will happen here?\n",
    "gray2 = gray_image//2\n",
    "plt.imshow(gray2, cmap='gray', vmin=0, vmax=255)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### examples of thresholding images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### numpy's benefit: full-array operations in one expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "[[ True  True  True]\n",
      " [ True False False]\n",
      " [False False False]]\n",
      "[[0 0 0]\n",
      " [0 5 6]\n",
      " [7 8 9]]\n"
     ]
    }
   ],
   "source": [
    "# numpy arrays are cleverer than plain lists...\n",
    "a = np.array( [ [1,2,3], [4,5,6], [7,8,9] ] )\n",
    "print(a)\n",
    "indices = a < 4.5\n",
    "print(indices)\n",
    "a[indices] = 0\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.]\n",
      " [ 0.  5.  6.]\n",
      " [ 7.  8.  9.]]\n",
      "[[0 0 0]\n",
      " [0 5 6]\n",
      " [7 8 9]]\n"
     ]
    }
   ],
   "source": [
    "# types are important!\n",
    "# numpy types: http://docs.scipy.org/doc/numpy-1.10.1/user/basics.types.html\n",
    "a = a.astype(float)\n",
    "print(a)\n",
    "a = a.astype(int)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### let's try with images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# here are some thresholded images\n",
    "image_gt142_indices = gray_image > 142\n",
    "image_gt142 = image.copy()\n",
    "image_gt142[image_gt142_indices] = 255\n",
    "image_gt142[np.logical_not(image_gt142_indices)] = 0\n",
    "# note that this shows how to take logical operators of index arrays..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(image_gt142, cmap='gray', vmin=0, vmax=255)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# you might try the thresholding challenge in the slides (with the spam image) here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# here are some thresholded images\n",
    "image_lt42_indices = gray_image < 42\n",
    "image_lt42 = image.copy()\n",
    "image_lt42[image_lt42_indices] = 255\n",
    "image_lt42[np.logical_not(image_lt42_indices)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_not_btw_42_142_indices = \\\n",
    "  np.logical_or(image_gt142_indices,image_lt42_indices)\n",
    "image_btw_42_142 = image.copy()\n",
    "image_btw_42_142[image_not_btw_42_142_indices] = 0\n",
    "image_btw_42_142[np.logical_not(image_not_btw_42_142_indices)] = 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# here is a 2d layout of images:\n",
    "fig, ax = plt.subplots(nrows=2, ncols=2, sharex=False, sharey=False)\n",
    "ax[0,0].imshow(image, cmap='gray');  #ax[0,0].set_title(\"orig\")\n",
    "ax[0,1].imshow(image_gt142, cmap='gray');  #ax[1,1].set_title(\"blue\")\n",
    "ax[1,0].imshow(image_btw_42_142, cmap='gray');  #ax[1,0].set_title(\"green\")\n",
    "ax[1,1].imshow(image_lt42, cmap='gray');  #ax[0,1].set_title(\"red\")\n",
    "\n",
    "for row in range(2):\n",
    "    for col in range(2):\n",
    "        ax[row,col].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fig = plt.figure()  # gets a new figure window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### let's try some of our own transformations..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for loops over the image - an all-blue image\n",
    "def example_filter( image ):\n",
    "    \"\"\" an example of a pixel-by-pixel filter \n",
    "        input: an r, g, b image\n",
    "        output: a transformed r, g, b image\n",
    "    \"\"\"\n",
    "    new_image = image.copy()\n",
    "    num_rows, num_cols, num_chans = new_image.shape\n",
    "    for row in range(num_rows):\n",
    "        for col in range(num_cols):\n",
    "            r, g, b = image[row,col]\n",
    "            new_image[row,col] = [b, b, b]\n",
    "    return new_image\n",
    "\n",
    "imge = fimage\n",
    "new_image = example_filter( image )\n",
    "plt.imshow(new_image)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# image filters (transformations from image to image)\n",
    "\n",
    "# for loops over the image\n",
    "def example_filter_bgr( image ):\n",
    "    \"\"\" an example of a pixel-by-pixel filter \n",
    "        input: an r, g, b image\n",
    "        output: a transformed r, g, b image\n",
    "    \"\"\"\n",
    "    new_image = image.copy()\n",
    "    num_rows, num_cols, num_chans = new_image.shape\n",
    "    for row in range(num_rows):\n",
    "        for col in range(num_cols):\n",
    "            r, g, b = image[row,col]\n",
    "            new_image[row,col] = [b, g, r]\n",
    "    return new_image\n",
    "\n",
    "\n",
    "def example_filter_gbr( image ):\n",
    "    \"\"\" an example of a pixel-by-pixel filter \n",
    "        input: an r, g, b image\n",
    "        output: a transformed r, g, b image\n",
    "    \"\"\"\n",
    "    new_image = image.copy()\n",
    "    num_rows, num_cols, num_chans = new_image.shape\n",
    "    for row in range(num_rows):\n",
    "        for col in range(num_cols):\n",
    "            r, g, b = image[row,col]\n",
    "            new_image[row,col] = [g, b, r]\n",
    "    return new_image\n",
    "\n",
    "\n",
    "def example_filter_inv( image ):\n",
    "    \"\"\" an example of a pixel-by-pixel filter \n",
    "        input: an r, g, b image\n",
    "        output: a transformed r, g, b image\n",
    "    \"\"\"\n",
    "    new_image = image.copy()\n",
    "    num_rows, num_cols, num_chans = new_image.shape\n",
    "    for row in range(num_rows):\n",
    "        for col in range(num_cols):\n",
    "            r, g, b = image[row,col]\n",
    "            new_image[row,col] = [255-r, 255-g, 255-b]\n",
    "    return new_image\n",
    "\n",
    "def example_filter_ig( image ):\n",
    "    \"\"\" an example of a pixel-by-pixel filter \n",
    "        input: an r, g, b image\n",
    "        output: a transformed r, g, b image\n",
    "    \"\"\"\n",
    "    new_image = image.copy()\n",
    "    num_rows, num_cols, num_chans = new_image.shape\n",
    "    for row in range(num_rows):\n",
    "        for col in range(num_cols):\n",
    "            r, g, b = image[row,col]\n",
    "            new_image[row,col] = [r, 255-g, b]\n",
    "    return new_image\n",
    "\n",
    "def example_filter_delbot2( image ):\n",
    "    \"\"\" an example of a pixel-by-pixel filter \n",
    "        input: an r, g, b image\n",
    "        output: a transformed r, g, b image\n",
    "    \"\"\"\n",
    "    new_image = image.copy()\n",
    "    num_rows, num_cols, num_chans = new_image.shape\n",
    "    for row in range(num_rows):\n",
    "        for col in range(num_cols):\n",
    "            r, g, b = image[row,col]\n",
    "            new_image[row,col] = [r>>2 << 2, g>>2<<2, b>>2 << 2]\n",
    "    return new_image\n",
    "\n",
    "def example_filter_deltop2( image ):\n",
    "    \"\"\" an example of a pixel-by-pixel filter \n",
    "        input: an r, g, b image\n",
    "        output: a transformed r, g, b image\n",
    "    \"\"\"\n",
    "    new_image = image.copy()\n",
    "    num_rows, num_cols, num_chans = new_image.shape\n",
    "    for row in range(num_rows):\n",
    "        for col in range(num_cols):\n",
    "            r, g, b = image[row,col]\n",
    "            new_image[row,col] = [r>>2 , g>>2, b>>2 ]\n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run all of these..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1:  write-your-own-filter\n",
    "\n",
    "Part A will be at least one filter that takes in a single image, transforms its pixels in an unusual way (something not in Photoshop's menu options, perhaps?), and then runs that filter on at least two of your own images.\n",
    "\n",
    "Part B will ask you to create at least one filter -- but one that combines _two_ images, meshing their pixels in a creative way, and outputting a single image. It's OK to resize the images so that they;re the same shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use the above examples as a starting point..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_filter( image ):\n",
    "    \"\"\" better docstring needed! \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def two_image_filter( image1, image2 ):\n",
    "    \"\"\" better docstring needed! \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2:  steganography\n",
    "\n",
    "This question asks you to write two functions, likely with some helper functions, that will enable you\n",
    "to embed arbitrary text (string) messages into an image (if there is enough room!) -- and then be\n",
    "able to extract an embedded message from an image, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let's do steganography!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# here is a signature for the encoding/embedding\n",
    "def steganographize( image, message ):\n",
    "    \"\"\" be sure to include a better docstring here! \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# here is a signature for the decoding\n",
    "def desteg_string( image ):\n",
    "    \"\"\" be sure to include a better docstring here! \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N, AB is 136 0101011101001111010101110010000001110100011010000110100101110011001000000111011101101111011100100110101101100101011001000010000100000000\n",
      "new_image.shape is (50, 50, 3)\n"
     ]
    }
   ],
   "source": [
    "# this is an example run (the code itself has been removed from this file!)\n",
    "\n",
    "# use the small image for testing\n",
    "raw_small = cv2.imread(\"small.png\",cv2.IMREAD_COLOR)\n",
    "small = cv2.cvtColor(raw_small, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(small)\n",
    "plt.show() \n",
    "\n",
    "# run steganographize\n",
    "new_small = steganographize( small, \"WOW this worked!\" )\n",
    "plt.imshow(new_small)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WOW this worked!'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and an example run of the message-decoding...\n",
    "desteg_string( new_small )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For extra credit, _image_ steganography...\n",
    "You might consider embedding an _image_ instead of a string using the\n",
    "same steganographic approach. One challenge that we leave open is how to _use_ the bits\n",
    "available, e.g., you could embed a three-bit grayscale image or even a color-image - that detail is up to you"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3:  chromakeying\n",
    "\n",
    "#### or, greenscreeing \n",
    "\n",
    "Here, we ask you to write a general-purpose green-screening function -- as an additional challenge, you'll also be able to remove the screened-in background after creating it!\n",
    "\n",
    "This final problem asks you to write two functions (as well as any helper functions): <tt>green_screen( original, new_background )</tt> and, optionally, <tt>de_green( screened_image )</tt>\n",
    "\n",
    "The first should remove the \"green\" (you'll have to create a definition of green) and find the foreground objects _within_ the green. It should return an image with those foreground objects placed on top of the new_background image (the second input). In addition, it should mark the result so \n",
    "\n",
    "The second function should be able to recover the foreground (or background) if you implement a \"de-greening\" feature in your approach to green-screening. That is, mark (using steganographic techniques) the pixels that are foreground (they were in front of the green screen) and background (everything else) - and then use that information to recover the original background + foreground where possible! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this is the signature for green_screening\n",
    "def green_screen( original, new_background ):\n",
    "    \"\"\" docstring needed... \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# and, if you like, try the de-greening!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Also, please include a markdown cell with a reflection and explanation \n",
    "# of your approach, your definition of green, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
